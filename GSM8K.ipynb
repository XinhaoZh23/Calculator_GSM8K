{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uSH__vQffr8D",
        "outputId": "9d6c4bc5-f1c4-4dfe-e64c-96d801240bf1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gradio in /usr/local/lib/python3.10/dist-packages (4.37.2)\n",
            "Requirement already satisfied: aiofiles<24.0,>=22.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (23.2.1)\n",
            "Requirement already satisfied: altair<6.0,>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.2.2)\n",
            "Requirement already satisfied: fastapi in /usr/local/lib/python3.10/dist-packages (from gradio) (0.111.0)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.10/dist-packages (from gradio) (0.3.2)\n",
            "Requirement already satisfied: gradio-client==1.0.2 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.0.2)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.27.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.23.4)\n",
            "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.4.0)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.1.4)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.1.5)\n",
            "Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.25.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.10.6)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio) (24.1)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.0.3)\n",
            "Requirement already satisfied: pillow<11.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (9.4.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.8.0)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.9 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.0.9)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.0.1)\n",
            "Requirement already satisfied: ruff>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.5.1)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: tomlkit==0.12.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.12.0)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.12.3)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.12.2)\n",
            "Requirement already satisfied: urllib3~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.0.7)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.30.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==1.0.2->gradio) (2023.6.0)\n",
            "Requirement already satisfied: websockets<12.0,>=10.0 in /usr/local/lib/python3.10/dist-packages (from gradio-client==1.0.2->gradio) (11.0.3)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (0.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (4.19.2)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (0.12.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (2024.6.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (1.0.5)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (3.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (3.15.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (4.66.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (4.53.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.1)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (2.20.0)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (13.7.1)\n",
            "Requirement already satisfied: starlette<0.38.0,>=0.37.2 in /usr/local/lib/python3.10/dist-packages (from fastapi->gradio) (0.37.2)\n",
            "Requirement already satisfied: fastapi-cli>=0.0.2 in /usr/local/lib/python3.10/dist-packages (from fastapi->gradio) (0.0.4)\n",
            "Requirement already satisfied: ujson!=4.0.2,!=4.1.0,!=4.2.0,!=4.3.0,!=5.0.0,!=5.1.0,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from fastapi->gradio) (5.10.0)\n",
            "Requirement already satisfied: email_validator>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from fastapi->gradio) (2.2.0)\n",
            "Requirement already satisfied: dnspython>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from email_validator>=2.0.0->fastapi->gradio) (2.6.1)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (23.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.18.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio) (1.16.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.16.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.24.1->gradio) (1.2.1)\n",
            "Requirement already satisfied: httptools>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn>=0.14.0->gradio) (0.6.1)\n",
            "Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.10/dist-packages (from uvicorn>=0.14.0->gradio) (1.0.1)\n",
            "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn>=0.14.0->gradio) (0.19.0)\n",
            "Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.10/dist-packages (from uvicorn>=0.14.0->gradio) (0.22.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.19.3->gradio) (3.3.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install gradio"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nhjeMPuTiNVr"
      },
      "source": [
        "### This code is used to randomly extract a subset of samples from the train.jsonl file for small-scale testing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ar4duehehmvH",
        "outputId": "7c15e677-2d5d-4cfc-87ce-487579b20599"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Question: Ryan is looking for people to crowdfund his new business idea.  If the average person funds $10 to a project they're interested in, how many people will Ryan have to recruit to fund a $1,000 business if he has $200 already?\n",
            "Question: John buys 1.5 ounces of silver and twice as much gold.  The silver costs $20 per ounce.  The gold is 50 times more expensive per ounce.  How much does he spend on everything?\n",
            "Question: It’s spring! The gardener at Parc Municipal orders flowers. He takes 250 tulips, 375 carnations and 320 roses. Each flower is sold for 2€. Calculate the total expenses.\n",
            "----\n",
            "Answer: First, we need to determine how much money Ryan needs to hit his goal which we find by subtracting his available cash from his target, performing 1000-200=<<1000-200=800>>800 dollars needed.\n",
            "Since the average person contributes $10 when crowdfunding, this means he needs to find 800/10=<<800/10=80>>80 people to fund his business well enough for him to hit his goal.\n",
            "#### 80\n",
            "Answer: He buys the silver for 1.5*$20=$<<1.5*20=30>>30\n",
            "He bought 1.5*2=<<1.5*2=3>>3 ounces of gold\n",
            "The gold is worth %20*50=$<<20*50=1000>>1000 per ounce\n",
            "So he buys 3*$1000=$<<3*1000=3000>>3000 on gold\n",
            "So he spent $30+$3000=$<<30+3000=3030>>3030 on everything\n",
            "#### 3030\n",
            "Answer: First we calculate the number of flowers: 250 + 375 + 320 = <<250+375+320=945>>945€\n",
            "Then the expense: 945 X 2 = <<945*2=1890>>1890€\n",
            "So, the total expenditure is €<<1890=1890>>1890.\n",
            "#### 1890\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import random\n",
        "\n",
        "def sample_questions_and_answers(filepath, sample_size=3):\n",
        "    # Read all questions and answers into two separate lists\n",
        "    questions = []\n",
        "    answers = []\n",
        "    with open(filepath, 'r', encoding='utf-8') as file:\n",
        "        for line in file:\n",
        "            qa_pair = json.loads(line.strip())\n",
        "            questions.append(qa_pair['question'])\n",
        "            answers.append(qa_pair['answer'])\n",
        "\n",
        "    # If the number of questions in the file is less than the requested sample size, print a warning\n",
        "    if len(questions) < sample_size:\n",
        "        print(\"Warning: The file contains fewer questions than the requested sample size.\")\n",
        "        sample_size = len(questions)\n",
        "\n",
        "    # Randomly select sample indices\n",
        "    sampled_indices = random.sample(range(len(questions)), sample_size)\n",
        "    # Extract questions and answers based on the indices\n",
        "    question_sample = [questions[i] for i in sampled_indices]\n",
        "    answer_sample = [answers[i] for i in sampled_indices]\n",
        "\n",
        "    return question_sample, answer_sample\n",
        "\n",
        "# Call the function and print the results\n",
        "filepath = 'train.jsonl'  # Replace with your file path\n",
        "question_sample, answer_sample = sample_questions_and_answers(filepath)\n",
        "\n",
        "for question in question_sample:\n",
        "    print(\"Question:\", question)\n",
        "print(\"----\")\n",
        "for answer in answer_sample:\n",
        "    print(\"Answer:\", answer)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eiXVIcjwiT2B"
      },
      "source": [
        "### Generate response for the data we extracted"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {
        "id": "tteHUnsDibqY"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"\" #Your Openai API Key"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dVoqF0zJk-v2",
        "outputId": "45159654-f93e-40bc-f3e0-3f31a3ae40b5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.35.13)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.27.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.8.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.6.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.20.0)\n"
          ]
        }
      ],
      "source": [
        "! pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mVAanUdNjuvU",
        "outputId": "7a220bf3-94f1-4108-8f8d-c8fe114abda1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPT Response: Ryan needs to raise $1,000 for his business idea and he already has $200. Therefore, he still needs to raise $1,000 - $200 = $800 more.\n",
            "\n",
            "If the average person funds $10, then Ryan will need $800 / $10 = 80 people to fund his business.\n",
            "----\n",
            "GPT Response: John buys 1.5 ounces of silver at $20 per ounce, so he spends 1.5 * $20 = $30 on silver.\n",
            "He buys twice as much gold as silver, so he buys 1.5 * 2 = 3 ounces of gold.\n",
            "Gold is 50 times more expensive per ounce than silver, so it costs 50 * $20 = $1000 per ounce.\n",
            "So he spends 3 * $1000 = $3000 on gold.\n",
            "Therefore, John spends $30 + $3000 = $3030 on everything.\n",
            "----\n",
            "GPT Response: To find the total expenses, we first need to calculate the total number of flowers ordered:\n",
            "\n",
            "Total number of flowers = 250 tulips + 375 carnations + 320 roses\n",
            "Total number of flowers = 945 flowers\n",
            "\n",
            "Next, we calculate the total cost of all the flowers:\n",
            "\n",
            "Total cost = Total number of flowers * Cost per flower\n",
            "Total cost = 945 flowers * 2€/flower\n",
            "Total cost = 1890€\n",
            "\n",
            "Therefore, the total expenses for the flowers ordered by the gardener at Parc Municipal is 1890€.\n",
            "----\n"
          ]
        }
      ],
      "source": [
        "import openai\n",
        "from datetime import datetime\n",
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI()\n",
        "\n",
        "def generate_gpt_answers(questions):\n",
        "    client = OpenAI(api_key='') # Your OpenAI API key\n",
        "    GPT_MODEL = \"gpt-3.5-turbo\"  # Can be replaced with the latest model version\n",
        "    response_sample = []\n",
        "\n",
        "    for question in questions:\n",
        "        messages = [\n",
        "            {\"role\": \"system\", \"content\": 'You are a tutor answering math questions.'},\n",
        "            {\"role\": \"user\", \"content\": question},\n",
        "        ]\n",
        "        response = client.chat.completions.create(\n",
        "            model=GPT_MODEL,\n",
        "            messages=messages,\n",
        "            temperature=0.5  # Adjust the temperature parameter to change the creativity of the answers\n",
        "        )\n",
        "        response_message = response.choices[0].message.content\n",
        "        response_sample.append(response_message)\n",
        "\n",
        "    return response_sample\n",
        "\n",
        "response_sample = generate_gpt_answers(question_sample)\n",
        "\n",
        "for response in response_sample:\n",
        "    print(\"GPT Response:\", response)\n",
        "    print(\"----\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iCVmKroY6RvP",
        "outputId": "de19d6dc-2f47-4910-d97a-60f78e8c3443"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Standardized Answer: \\boxed{}\n",
            "Standardized Answer: \\boxed{3030}\n",
            "Standardized Answer: \\boxed{1890}\n"
          ]
        }
      ],
      "source": [
        "def standardize_answers(response_sample):\n",
        "    client = OpenAI(api_key='')\n",
        "    GPT_MODEL = \"gpt-3.5-turbo-1106\"  # Can be replaced with the latest model version\n",
        "    standardize_sample = []\n",
        "\n",
        "    # Construct standardization requests for each answer\n",
        "    for response in response_sample:\n",
        "        # Send request to the GPT model to standardize the answer\n",
        "        messages = [\n",
        "            {\"role\": \"system\", \"content\": 'Extract and format the answer in a standardized form, enclosed within \\\\boxed{}. OUTPUT ONLY THE RESULT NUMBER, DO NOT ADD ADDITIONAL CONTENT.'},\n",
        "            {\"role\": \"user\", \"content\": response},\n",
        "        ]\n",
        "        response = client.chat.completions.create(\n",
        "            model=GPT_MODEL,\n",
        "            messages=messages,\n",
        "            temperature=0  # Use temperature 0 to get the most consistent output\n",
        "        )\n",
        "        response_message = response.choices[0].message.content\n",
        "        # Extract only the content within \\boxed{}\n",
        "        if '\\\\boxed{' in response_message:\n",
        "            # Use simple text processing to extract the content within \\boxed{}\n",
        "            start = response_message.find('\\\\boxed{') + len('\\\\boxed{')\n",
        "            end = response_message.find('}', start)\n",
        "            boxed_content = response_message[start:end]\n",
        "            standardized_response = f\"\\\\boxed{{{boxed_content}}}\"\n",
        "        else:\n",
        "            # If the standard format cannot be recognized, return the original response, though this should not happen\n",
        "            standardized_response = f\"\\\\boxed{{}}\"\n",
        "\n",
        "        standardize_sample.append(standardized_response)\n",
        "\n",
        "    return standardize_sample\n",
        "\n",
        "standardized_sample = standardize_answers(response_sample)\n",
        "\n",
        "for answer in standardized_sample:\n",
        "    print(\"Standardized Answer:\", answer)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {
        "id": "hk-eadvVri07"
      },
      "outputs": [],
      "source": [
        "def create_eval_json_file(question_sample, answer_sample, response_sample, standardized_sample, filepath=\"eval_result.json\"):\n",
        "    with open(filepath, \"w\", encoding='utf-8') as f:\n",
        "        for idx, (question, answer, response, standardized_answer) in enumerate(zip(question_sample, answer_sample, response_sample, standardized_sample)):\n",
        "\n",
        "            # Extract the text after '###' from the answer as the final answer\n",
        "            final_answer = answer.split('###')[-1].strip().lstrip('# ')\n",
        "\n",
        "            # Extract the number or text from standardized_answer\n",
        "            if '\\\\boxed{' in standardized_answer:\n",
        "                start = standardized_answer.find('\\\\boxed{') + len('\\\\boxed{')\n",
        "                end = standardized_answer.find('}', start)\n",
        "                standardized_answer_content = standardized_answer[start:end]\n",
        "            else:\n",
        "                standardized_answer_content = ''  # Return an empty string if the format is incorrect\n",
        "\n",
        "            # Compare the final answer with the standardized answer to check for consistency\n",
        "            is_correct = (final_answer == standardized_answer_content)\n",
        "\n",
        "            # Construct JSON object\n",
        "            data = {\n",
        "                \"question\": question,\n",
        "                \"answer\": answer,\n",
        "                \"pred_answer\": response,\n",
        "                \"standardized_answer\": standardized_answer,\n",
        "                \"is_correct\": is_correct  # Update based on the answer comparison result\n",
        "            }\n",
        "            # Write to file\n",
        "            json_line = json.dumps(data)\n",
        "            f.write(json_line + \"\\n\")\n",
        "\n",
        "# Create JSONL file\n",
        "create_eval_json_file(question_sample, answer_sample, response_sample, standardized_sample)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "taf2qXCLnT4H"
      },
      "source": [
        "### Evaluate the correctness of the answer generate by GPT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 645
        },
        "id": "7U2SuLS1qsIa",
        "outputId": "99abb7c4-7a49-46d7-f139-e78ada919aa8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://f333a63cf1978ab608.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://f333a63cf1978ab608.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": []
          },
          "execution_count": 125,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "# Human Evaluation for GSM8K\n",
        "import json\n",
        "import gradio as gr\n",
        "\n",
        "def read_samples():\n",
        "    with open(\"eval_result.json\", \"r\") as f:\n",
        "        data = f.readlines()\n",
        "\n",
        "    content = []\n",
        "    cnt = 0\n",
        "    for sample in data:\n",
        "        sample_dict = json.loads(sample.strip())\n",
        "        # Modified logic: include samples that do not contain '\\\\boxed' or have 'is_correct' as false\n",
        "        if ('\\\\boxed' not in sample_dict['standardized_answer']) or (not sample_dict['is_correct']):\n",
        "            cnt += 1\n",
        "            # Add standardized_answer column\n",
        "            content.append([cnt,\n",
        "                            sample_dict['question'],\n",
        "                            sample_dict['answer'].split('####')[-1].strip(),\n",
        "                            sample_dict['standardized_answer'],  # Show standardized answer\n",
        "                            sample_dict['pred_answer'],\n",
        "                            'F'])  # Default value for human evaluation\n",
        "    return content\n",
        "\n",
        "def get_human_eval(df):\n",
        "    # get model evaluation\n",
        "    with open(\"eval_result.json\", \"r\") as f:\n",
        "        data = f.readlines()\n",
        "\n",
        "    model_true_cnt = 0\n",
        "    for sample in data:\n",
        "        sample_dict = json.loads(sample.strip())\n",
        "        if '\\\\boxed' in sample_dict['standardized_answer'] and sample_dict['is_correct']:\n",
        "            model_true_cnt += 1\n",
        "    # get human evaluation\n",
        "    human_true_cnt = 0\n",
        "    for i, row in df.iterrows():\n",
        "        # Check if Human Evaluation is 'T' for True\n",
        "        if row['Human Evaluation'] == 'T':\n",
        "            human_true_cnt += 1\n",
        "    total_entries = len(data)\n",
        "    total_correct = model_true_cnt + human_true_cnt\n",
        "    total_accuracy = total_correct / total_entries\n",
        "    return (f\"Update {human_true_cnt} samples with human evaluation, \\n\"\n",
        "            f\"Total Accuracy: {total_correct}/{total_entries} = {total_accuracy:.2%}\")\n",
        "\n",
        "with gr.Blocks() as demo:\n",
        "    with gr.Column():\n",
        "        with gr.Row():\n",
        "            table = gr.DataFrame(label='Table',\n",
        "                                 value=read_samples(),\n",
        "                                 headers=['No.', 'Question', 'Answer', 'Standardized Answer', 'Prediction', 'Human Evaluation'],\n",
        "                                 interactive=True,\n",
        "                                 wrap=True)\n",
        "        with gr.Row():\n",
        "            output = gr.Textbox(label='Human Evaluation')\n",
        "            submit = gr.Button(\"Search\")\n",
        "\n",
        "        submit.click(fn=get_human_eval,\n",
        "                     inputs=table,\n",
        "                     outputs=output)\n",
        "\n",
        "demo.launch()\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
